<!--
Viewer for sequential matches in a chronologically numbered sequence of images e.g. 0000.jpg, 0001.jpg, 0002.jpg, ...

Sequence does not have to be contiguous. Currently only 3-character file extension supported, though should be easy to improve.

Pass the relevant OpenSfM data directory in the #dir parameter.

Directory must end in forward slash: data/lund/ instead of data/lund. Silly requirement, but inertia permits it.

Example usage: http://localhost:8000/viewer/matches.html#dir=data/berlin/

Initially, no image will appear, since the texture loads after the initial render. Doing things will update the view.

Controls:

Scroll to zoom in/out of the *centre* of the world. Zoom-to-pointer not currently supported.

Pan via left-click and drag. Use this to zoom to arbitrary points.
Beware that pan is in world units, not camera units. Somewhat surgical precision is required when panning at high zoom levels, else it moves too fast.

Navigate forwards in time (well, file number order) using up arrow key. Backwards using down arrow key.

Note: in what follows, "previous" means "previous in filename order", not "the most recent image you viewed", since you can move backward as well as forward.

Features in the current image, that OpenSfM thinks also appeared in the previous one, are highlighted with yellow outlines.
Their size is constant regardless of zoom level, as they are only associated with points and colours in the OpenSfM output.
They are filled with their associated feature colour, although this is easier to notice when significantly zoomed out.

A blue line connects each matched feature with its previous position. It shows how much the feature moved from the previous image.

Features that did *not* appear in the previous image have faint grey outlines.

-->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
    <style>
			body {
                margin: 0px;
            }
    </style>
</head>
<body>
    <div id="ThreeJS" target="_blank"></div>
    <script src="js/jquery.js"></script>
    <script src="js/three.js"></script>
    <script type="x-shader/x-vertex" id="feature_vsh">
    attribute vec4 outline;

    varying vec3 v_color;
    varying vec4 v_outline;
    void main() {
        v_color = color;
        v_outline = outline;
        gl_PointSize = 20.0;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
    }
    </script>
    <script type="x-shader/x-fragment" id="feature_fsh">
    varying vec3 v_color;
    varying vec4 v_outline;
    void main() {
        vec2 cxy = 2.0 * gl_PointCoord - 1.0;
        float r2 = dot(cxy, cxy); // Quadrance of point coord from centre of point
        vec2 df = vec2(dFdx(r2), dFdy(r2));
        float delta = length(df);
        float r_fill = 1.0 - 3.0*delta;        // radius of end of fill color (approx 3px from edge)
        float r_fill_outline = r_fill + delta; // radius of beginning of outline (approx 2px)
        float r_outline = 1.0-delta;           // radius of end of outline (approx 1px)
        float r_outline_outside = 1.0;         // radius of beginning of exterior (edge)

        // max is to prioritise outline color over edge color in limiting case.
        // antialias transitions between fill and outline, outline and outside
        float alpha_fill_outl = smoothstep(max(r_fill, 0.0), max(r_fill_outline, 0.0), r2);
        float alpha_outl_outs = smoothstep(max(r_outline, 0.0), r_outline_outside, r2);
        vec4 color = vec4(mix(v_color, v_outline.rgb, alpha_fill_outl), v_outline.a);
        color.a = mix(color.a, 0.0, alpha_outl_outs);
        gl_FragColor = color;
    }
    </script>
    <script>
        let scene = new THREE.Scene();

        let loader = new THREE.TextureLoader();

        let renderer = new THREE.WebGLRenderer();
        let width = window.innerWidth * 0.99;
        let height = window.innerHeight * 0.99;

        {
            let DPR = (window.devicePixelRatio) ? window.devicePixelRatio : 1;

            renderer.setPixelRatio(DPR);
            renderer.setSize(width, height);
        }

        let wndAspect = width / height;

        let container = document.getElementById("ThreeJS");
        container.appendChild(renderer.domElement);

        let url = {
            tracks: "http://localhost:8000/data/dartmoor-small/5/tracks.json",
            image: "http://localhost:8000/data/dartmoor-small/5/images/",
            reconstr: "http://localhost:8000/data/dartmoor-small/5/reconstruction.json"
        };

        let startImage = 0;

        (function() {
            let match,
                pl     = /\+/g,  // Regex for replacing addition symbol with a space
                search = /([^&=]+)=?([^&]*)/g,
                decode = function (s) { return decodeURIComponent(s.replace(pl, " ")); },
                hash  = window.location.hash.substring(1);

            url.params = {};
            while (match = search.exec(hash))
               url.params[decode(match[1])] = decode(match[2]);
        }) ();

        {
            let dir = url.params["dir"];
            if (dir) {
                let prefix = "http://localhost:8000/" + dir;
                url.tracks = prefix + "tracks.json";
                url.image = prefix + "images/";
                url.reconstr = prefix + "reconstruction.json";
            }
        }

        /*let numToFilename;
        {
            let filename = url.params["start"];
            let numDigits = 8;
            let ext = ".jpg";

            if (filename) {
                let structure = /\D*(\d+)(\..+)/;
                let matches = structure.exec(filename);
                numDigits = matches[1].length;
                ext = matches[2];
            }

            numToFilename = function(num) {
                return num.toLocaleString("en", { minimumIntegerDigits: numDigits })+ext;
            };

        }*/

        // adds "track_id" field to each track, returns new array sorted smallest-to-largest track_id
        let tracksToArray = function(tracks) {
            let arr = [];
            for (let [tid, obj] of Object.entries(tracks)) {
                obj.track_id = tid; // Transfer to obj
                arr.push(obj);
            }
            arr.sort( (t1, t2) => t1.track_id - t2.track_id );
            return arr;
        };

        // identify elements that occur in both arrays; marked in t2 as <track>.twin
        // algorithm assumes arrays have been sorted smallest-to-largest
        let intersectTrackArrays = function(t1, t2) {
            let i1 = 0; // points to what we are currently considering within t1
            let i2 = 0; // likewise for t2

            let matched = 0;

            while (i1 < t1.length && i2 < t2.length) {
                let obj1 = t1[i1], obj2 = t2[i2];

                let tid1 = +obj1.track_id, tid2 = +obj2.track_id; // convert to int, so comparisons don't screw up...

                if (tid1 === tid2) {
                    obj2.twin = obj1; // mark
                    matched++;
                    i2++; // if advanced i1++ as well, would skip duplicates. not sure about that
                } else if (tid1 < tid2) {
                    if (i1 === t1.length - 1) break; // because i2 is sorted, no chance of a further match
                    else i1++;
                } else {
                    if (i2 === t2.length - 1) break; // likewise for i1
                    else i2++;
                }
            }
        };

        // Used from perspective of (member of tracks) "coming from" its twin.
        // i.e. twin comes first, then step forward to (member of tracks). Draw delta from former to latter.
        let calcDeltaGeom = function(tracks) {
            let geom = new THREE.Geometry();

            for (let track of tracks) {
                if (track.twin !== undefined) {
                    let p1 = track.coords, p2 = track.twin.coords;

                    geom.vertices.push(new THREE.Vector3(p2[0], p2[1], 0));
                    geom.vertices.push(new THREE.Vector3(p1[0], p1[1], 0));
                }
            }

            return geom;
        };

        let reconstr;

        let scale = 10;

        // Initialises geometry.
        // input `tracks` contains objects like
        // { coords: [x, y], color: [100, 200, 255] /* r,g,b */ }
        function FeatureCloud(tracks) {
            let positions = [], colors = [], outlines = [];

            let zMatch = 0, zBoring = 0;
            for (let track of tracks) {
                let pos = track.coords;

                let color = track.color;
                colors.push(color[0] / 255., color[1] / 255., color[2] / 255.);

                if (track.twin === undefined) {
                    outlines.push(0.0, 0.0, 0.0, 0.2);
                    positions.push(pos[0], pos[1], zBoring*0.0001);
                    zBoring++;
                } else {
                    outlines.push(1.0, 1.0, 0.0, 1.0);
                    positions.push(pos[0], pos[1], 1.0 + zMatch*0.0001);
                    zMatch++;
                }
            }

            let geom = new THREE.BufferGeometry(); // Needed for custom attributes, I think

            positions   = new Float32Array(positions);
            colors      = new Float32Array(colors);
            outlines    = new Float32Array(outlines);

            positions   = new THREE.BufferAttribute(positions   , 3);
            colors      = new THREE.BufferAttribute(colors      , 3);
            outlines    = new THREE.BufferAttribute(outlines    , 4);

            geom.addAttribute("position", positions);
            geom.addAttribute("color"   , colors);
            geom.addAttribute("outline" , outlines);

            if (FeatureCloud.prototype.material === undefined) {
                FeatureCloud.prototype.material = new THREE.ShaderMaterial({
                    extensions: { derivatives: true },
                    vertexColors: THREE.VertexColors,
                    side: THREE.DoubleSide,
                    transparent: true,
                    vertexShader: $("#feature_vsh").text(),
                    fragmentShader: $("#feature_fsh").text(),
                });
            }

            this.threeObject = new THREE.Points(geom, FeatureCloud.prototype.material);

        };
        FeatureCloud.prototype = {};

        let ImageQuad = function(aspect, texture) {
            let geom = new THREE.Geometry();

            let dy = 0.5, dx = aspect * dy;

            geom.vertices.push(new THREE.Vector3(-dx, -dy, 0)); // bottom left
            geom.vertices.push(new THREE.Vector3(-dx, dy, 0)); // top left
            geom.vertices.push(new THREE.Vector3(dx, dy, 0)); // top right
            geom.vertices.push(new THREE.Vector3(dx, -dy, 0)); // bottom right

            geom.faces.push(new THREE.Face3(0, 2, 1));
            geom.faces.push(new THREE.Face3(0, 3, 2));

            geom.faceVertexUvs[0].push([new THREE.Vector2(0, 0), new THREE.Vector2(1, 1), new THREE.Vector2(0, 1)]);
            geom.faceVertexUvs[0].push([new THREE.Vector2(0, 0), new THREE.Vector2(1, 0), new THREE.Vector2(1, 1)]);

            let mat = new THREE.MeshBasicMaterial({ map: texture });

            this.threeObject = new THREE.Mesh(geom, mat);
        };
        ImageQuad.prototype = {};

        jQuery.when(jQuery.getJSON(url.tracks), jQuery.getJSON(url.reconstr)).done((tdata, rdata) => {
            // jQuery seems to wrap results in random guff
            tdata = tdata[0]; rdata = rdata[0];
            // Pick reconstruction 0
            reconstr = rdata[0];

            let Snapshot = function(filename) {
                Snapshot.namesMap[filename] = this;

                let tracks = tdata[filename];
                let camera_name = reconstr.shots[filename].camera;
                let camera = reconstr.cameras[camera_name];
                let aspect = camera.width / camera.height;

                let threeObject = new THREE.Object3D();

                let texture = loader.load(url.image+filename);
                texture.wrapS = THREE.ClampToEdgeWrapping;
                texture.wrapT = THREE.ClampToEdgeWrapping;
                texture.minFilter = THREE.LinearFilter;

                let quad = new ImageQuad(aspect, texture);
                threeObject.add(quad.threeObject);

                quad.threeObject.position.copy(new THREE.Vector3(0, 0, -1));
                quad.threeObject.scale.multiplyScalar(10);

                this.tracks = tracksToArray(tracks);

                if (Snapshot.prevCreated !== undefined) {
                    let prev = Snapshot.prevCreated;
                    this.prev = prev;
                    prev.next = this;

                    intersectTrackArrays(prev.tracks, this.tracks);
                    let geom = calcDeltaGeom(this.tracks);

                    let deltaMat = new THREE.LineBasicMaterial({ color: 0x00ffff });
                    let delta = new THREE.LineSegments(geom, deltaMat);

                    delta.scale.set(1, -1, 1).multiplyScalar(aspect*10);
                    delta.position.copy(new THREE.Vector3(0, 0, 10));
                    threeObject.add(delta);
                }

                let featureCloud = new FeatureCloud((function* () { // iterate through possibly twinned tracks
                    for (let tid of Object.keys(tracks)) { yield tracks[tid]; }
                })());

                featureCloud.threeObject.scale.set(aspect*10, -aspect*10, 1);
                threeObject.add(featureCloud.threeObject);

                this.filename = filename;
                this.aspect = aspect;
                this.threeObject = threeObject;
                Snapshot.prevCreated = this;
            };
            Snapshot.namesMap = {};
            Snapshot.byFilename = function(filename) {
                return this.namesMap[filename];
            };

            let namesInOrder = Object.keys(reconstr.shots).sort((n1, n2) => {
                n1 = +n1.substring(0, n1.length - 4); // no ".jpg", parse to int
                n2 = +n2.substring(0, n2.length - 4); // ditto
                return n1 - n2;
            });

            for (let i=0; i<namesInOrder.length; i++) { // Preload EVERYTHING!!
                let name = namesInOrder[i];
                new Snapshot(name);
            }

            let current = Snapshot.byFilename(namesInOrder[0]);
            scene.add(current.threeObject);

            // Fit camera to image, while keeping window aspect ratio
            let camWidth = 10*current.aspect, camHeight = 10; // image width, image height

            if (camWidth >= camHeight) {
                camHeight = camWidth / wndAspect; // keep view as wide as image, and stretch vertically
            } else {
                camWidth = camHeight * wndAspect; // keep view as tall as image, and stretch horizontally
            }

            let camera = new THREE.OrthographicCamera(-camWidth/2, camWidth/2, camHeight/2, -camHeight/2, 0.1, 1000);
            camera.position.z = 50;
            camera.lookAt(new THREE.Vector3(0, 0, 0));
            scene.add(camera);

            let render = function () {
                renderer.render(scene, camera);
            };

            let changeSnapshot = function(newSnap) {
                if (newSnap === undefined) return;

                scene.remove(current.threeObject);
                scene.add(newSnap.threeObject);

                current = newSnap;
            };

            let panning = false;
            let raycaster = new THREE.Raycaster();
            let velocity = new THREE.Vector3();
            raycaster.precision = 0.01;

            let events = {
                keyDown: function(event) {
                    switch (event.key) {
                        case "ArrowDown":
                            changeSnapshot(current.prev);
                            break;
                        case "ArrowUp":
                            changeSnapshot(current.next);
                            break;
                    }
                    render();
                },
                keyUp: function(event) {},
                mouseDown: function(event) {
                    panning = true;
                    prevStep = undefined;
                },
                mouseUp: function(event) {
                    panning = false;
                },
                mouseMove: function(event) {
                    if (panning) {
                        velocity.x = event.movementX; // Pixels left-to-right
                        velocity.y = event.movementY; // Pixels top-to-bottom

                        velocity.x /= width; // now, proportion of camera width, L2R
                        velocity.y /= height; // now, proportion of camera height, T2B

                        velocity.x *= -1; // now, velocity is in the direction I want the camera to move
                        // i.e. mouse down -> camera up, mouse left -> camera right

                        velocity.multiplyScalar(5); // empirically nice

                        camera.position.add(velocity);
                        render();
                    }
                },
                mouseWheel: function(event) {
                    event.preventDefault(); event.stopPropagation();

                    let zoom = event.deltaY;
                    if (zoom > 0) {
                        zoom = 1.1;
                    } else {
                        zoom = 0.9;
                    }
                    camera.scale.multiply(new THREE.Vector3(zoom, zoom, 1));

                    render();
                }
            };
            window.addEventListener("mousemove", events.mouseMove, false);
            window.addEventListener("mousedown", events.mouseDown, false);
            window.addEventListener("mouseup", events.mouseUp, false);
            window.addEventListener("contextmenu", function ( event ) { event.preventDefault(); }, false );
            window.addEventListener("mousewheel", events.mouseWheel, false );
            window.addEventListener("keyup", events.keyUp, false );
            window.addEventListener("keydown", events.keyDown, true );

            // TODO: Smooth pan, zoom to cursor

            render();
        });
    </script>
</body>
</html>